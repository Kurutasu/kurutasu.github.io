---
layout: post
title:  "【G検定】チートシート"
updated: 2021-02-18
cover:  "/assets/cover_image.jpg"
subheadline:  "G検定まとめ"
categories: 
- AI
---

# はじめに

* [一般社団法人 日本ディープラーニング協会　G検定](https://www.jdla.org/certificate/general/)

* ディープラーニングG検定に向けた情報整理を行う。

* 構成は[シラバス](https://www.jdla.org/certificate/general/#general_No03)に従い、該当項目には「📘」を付す。

* 参考図書

    [ディープラーニング G検定(ジェネラリスト) 公式テキスト](https://www.amazon.co.jp/dp/4798157554)

* 模擬テスト

    [Study-AI G検定 模擬テスト](http://study-ai.com/generalist/)

# １．📘人工知能（AI）とは（人工知能の定義）

## AIの定義

* 専門家の間で共有されている定義はない。

* 人工知能であるかどうかは「人によって違う」。

* 定義の例

    * 「推論、認識、判断など、人間と同じ知的な処理能力を持つ機械（情報処理システム）」
    
    * 「周囲の状況（入力）によって行動（出力）を変えるエージェント（プログラム）」

    * 🎩松尾豊
    
        「人工的につくられた人間のような知能、ないしはそれをつくる技術」

    * 🎩アーサー・サミュエル

        「明示的にプログラムしなくても学習する能力をコンピュータに与える研究分野」

## 人工知能レベル

* レベル1

    シンプルな制御プログラム。**ルールベース**。
 
* レベル2

    古典的な人工知能。**探索・推論**を行う。知識データを利用する。
 
* レベル3

    [**機械学習**](https://d.hatena.ne.jp/keyword/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92)を取り入れた人工知能。多くのデータから入力・出力関係を学習する。
 
* レベル4   

    [**ディープラーニング**](https://d.hatena.ne.jp/keyword/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0)を取り入れた人工知能。特徴量による学習を行う。

## AI効果

* [人工知能](https://d.hatena.ne.jp/keyword/%E4%BA%BA%E5%B7%A5%E7%9F%A5%E8%83%BD)の原理がわかると「単純な自動化である」とみなしてしまう人間の心理のこと。

## ロボットとの違い

* [人工知能](https://d.hatena.ne.jp/keyword/%E4%BA%BA%E5%B7%A5%E7%9F%A5%E8%83%BD)では「考える」という、目に見えないものを中心に扱っている。

* [人工知能](https://d.hatena.ne.jp/keyword/%E4%BA%BA%E5%B7%A5%E7%9F%A5%E8%83%BD)ではロボットの「脳の部分」を扱っている。（脳だけ、というわけではない）

* ロボットの研究者は[人工知能](https://d.hatena.ne.jp/keyword/%E4%BA%BA%E5%B7%A5%E7%9F%A5%E8%83%BD)の研究者というわけではない。

## 歴史

### ✅ 💻ENIAC

* 1946年、アメリカ ペンシルバニア大学。

* 世界初の汎用電子式コンピュータ。

    ![](https://upload.wikimedia.org/wikipedia/commons/6/6c/ENIAC_Penn1.jpg)

### ✅ ダートマス会議

* 1956年、アメリカで開催。

* 🎩ジョン・マッカーシーが初めて「人工知能（AI）」という言葉を使った。

* 世界初の人工知能プログラムといわれる💻[ロジック・セオリスト](https://ja.wikipedia.org/wiki/Logic_Theorist)のデモを実施した。

    ![](https://miro.medium.com/max/1000/0*8MW8iP2QC_WNhmiW)

### ✅ 第１次AIブーム

* **推論・探索** が中心。

* **トイ・プロブレム（おもちゃの問題）** は解けても、現実の問題は解けないことが判明。

    ⇒ 失望へ

### ✅ 第２次AIブーム

* 💻**エキスパートシステム**が流行し、[ナレッジエンジニア](https://www.weblio.jp/content/%E3%83%8A%E3%83%AC%E3%83%83%E3%82%B8%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2)が必要とされた。

    ```
    ナレッジエンジニアとは、
    人工知能（AI）を応用したシステム構築を専門とする技術者（エンジニア）のことである。（引用）
    ```

* 日本

    💻**第五世代コンピュータ**という大型プロジェクトを推進、エキスパートシステム等に取り組んだ。

* 知識の蓄積・管理は大変！ということに気づく。

    ```
    第五世代コンピュータとは、
    通商産業省（現経済産業省）が1982年に立ち上げた国家プロジェクトの開発目標である。（引用）
    ```

    ⇒ 失望へ

### ✅ 第３次AIブーム

* **機械学習・特徴表現**が中心。

* ビッグデータによる**機械学習**、特徴量による**ディープラーニング（深層学習）** が流行。

# ２．📘人工知能をめぐる動向

# 2-1.📘探索・推論

## 探索・推論の手法

### ✅ 探索木

* 幅優先探索

    最短距離の解が必ずわかる。すべてを記憶するためメモリ容量が必要。

    ![](https://upload.wikimedia.org/wikipedia/commons/b/bc/Breadth-first-tree.png)

* 深さ優先探索

    メモリは少なめでよいが、最短距離が必ずわかるわけではない。

    ![](https://upload.wikimedia.org/wikipedia/commons/5/5d/Depth-first-tree.png)

### ✅ [ハノイの塔](https://ja.wikipedia.org/wiki/%E3%83%8F%E3%83%8E%E3%82%A4%E3%81%AE%E5%A1%94)

* 以下のルールに従ってすべての円盤を右端の杭に移動させられれば完成。

    * 3本の杭と、中央に穴の開いた大きさの異なる複数の円盤から構成される。

    * 最初はすべての円盤が左端の杭に小さいものが上になるように順に積み重ねられている。

    * 円盤を一回に一枚ずつどれかの杭に移動させることができるが、小さな円盤の上に大きな円盤を乗せることはできない。

    ![](https://upload.wikimedia.org/wikipedia/commons/6/60/Tower_of_Hanoi_4.gif)

### ✅ ロボットの行動計画

* [プランニング](https://ja.wikipedia.org/wiki/%E8%87%AA%E5%8B%95%E8%A8%88%E7%94%BB)

    * オフラインプランニング・静的プランニング

        周囲の状況が既知で、その構造がよく理解されている場合に、行動の計画や戦略をあらかじめ組み立てて(計算して）おくこと。

    * オンラインプランニング・動的プランニング

        未知の環境において、周囲の状況が明らかになるにつれて行動の計画や戦略を修正すること。

    * リプランニング

        計画・戦略を修正すること。

* STRIPS

    * Stanford Research Institute Problem Solver

    * 自動計画に関する人工知能の一種。

    * 前提条件、行動、結果を記述する。

* SHRDLU

    * 1970年、スタンフォード大学、🎩テリー・ウィノグラード。

    * 英語の指示により画面上の積み木を動かす。

    * 成果はCycプロジェクトに引き継がれている。

    * 【Youtube】SHRDLU in Action

        [![](https://img.youtube.com/vi/bo4RvYJYOzI/0.jpg)](https://youtu.be/bo4RvYJYOzI "SHRDLU in Action")
    
### ✅ ボードゲーム

* 1996年、💻**IBM DeepBlue（ディープブルー）。「[力任せの探索](https://ja.wikipedia.org/wiki/%E5%8A%9B%E3%81%BE%E3%81%8B%E3%81%9B%E6%8E%A2%E7%B4%A2)」だったが、チェスの世界チャンピオンを破った。

    ```
    力まかせ探索（Brute-force search）またはしらみつぶし探索（Exhaustive search）は、
    単純だが非常に汎用的な計算機科学の問題解決法であり、
    全ての可能性のある解の候補を体系的に数えあげ、
    それぞれの解候補が問題の解となるかをチェックする方法である。（引用）
    ```

* 2012年、💻ボンクラーズ が将棋において永世棋聖に勝利。

* 2013年、💻ponanza が将棋において現役プロ棋士に勝利。

* 2016年、💻AlphaGo（アルファ碁）が韓国のプロ棋士に勝利。

    ディープラーニングが使われた。

    ![](https://tech-camp.in/note/wp-content/uploads/alphago-1024x519.png)

* 2017年、💻elmo が世界コンピュータ将棋選手権において ponanza に勝利。elmo 同士の対戦を行うことで学習を行った。

### ✅ コスト

* 効率よく探索するため、時間や費用といったコストの概念を取り入れている。

* ヒューリスティックな知識を利用して探索を短縮することができる。

    ※ヒューリスティック：経験則の、試行錯誤的な

### ✅ [Mini-Max法](https://ja.wikipedia.org/wiki/%E3%83%9F%E3%83%8B%E3%83%9E%E3%83%83%E3%82%AF%E3%82%B9%E6%B3%95)

* ゲーム戦略で利用される。

* 想定される「最大の損害」が最小になるように決断を行う戦略のこと。

* 自分の番はスコア最大、相手の番はスコア最小になるような戦略をとる。

* この手法は全探索を行うため効率が悪い。

### ✅ [α-β法](https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%AB%E3%83%95%E3%82%A1%E3%83%BB%E3%83%99%E3%83%BC%E3%82%BF%E6%B3%95)

* Mini-Max法の応用アルゴリズム。

* 読む必要のない手を打ち切ることで高速化を図っている。

* αカットは関心範囲の最小値のカット、βカットは最大値のカットを行う。

### ✅ モンテカルロ法

* 特徴：

    プレイアウト（ゲームを一度終局までもっていく）の結果、どの方法が一番勝率が高いかを評価する。

* デメリット：

    ブルートフォース（力任せな方法）のため、組合せが多いと計算しきれない。

# 2-2.📘知識表現

## 知識表現

### ✅ 💻ELIZA（イライザ）

* 1966年、🎩ジョセフ・ワイゼンバウム。

* 「人工無能」の元祖。精神科セラピストを演じた。

* パターンに合致したら返答する「ルールベース」である。

* イライザ効果：あたかも本物の人間と話しているように錯覚すること。

* その後開発された💻PARRYと会話した記録が残されており（RFC439）、中でもICCC1972が有名。

    ![](https://upload.wikimedia.org/wikipedia/commons/4/4e/ELIZA_conversation.jpg)

## ✅ エキスパートシステム

### ✓ 💻DENDRAL

* 1960年代、スタンフォード大学　🎩エドワード・ファイゲンバウム。

* 未知の有機化合物を特定する。質量分析法で分析する。

    ```
    質量分析法とは、
    分子をイオン化し、そのm/zを測定することによってイオンや分子の質量を測定する分析法である。（引用）。
    ```

### ✓ 💻マイシン（MYCIN）

* 1970年、スタンフォード大学。

* ルールベースで血液中のバクテリアの診断支援を行った。

* 正解確率の高い細菌名のリスト、信頼度、推論理由、推奨される薬物療法コースを示した。

* 精度は専門医の80%に対し、69%であった。

## ✅ 意味ネットワーク

* semantic network

* 人間の記憶の一種である意味記憶の構造を表すためのモデル。

* 単語同士の意味関係をネットワークによって表現する。

* 概念を表す節（ノード）と、概念の意味関係を表す辺（エッジ）からなる、有向グラフまたは無向グラフである。

    ```
    無向グラフのエッジには方向性がありません。
    エッジは "双方向" の関係を示します。 
    有向グラフのエッジには方向性があります。エッジは "一方向" の関係を示します。（引用）
    ```

    ![](https://upload.wikimedia.org/wikipedia/commons/thumb/6/67/Semantic_Net.svg/305px-Semantic_Net.svg.png)


## ✅ [Cycプロジェクト](https://www.cyc.com/)

* 1984年、🎩ダグラス・レナート。

* すべての一般知識を取り込もうという活動。

* 2001年からはOpenCycとして公開されている。

## [オントロジー（ontology）](https://ja.wikipedia.org/wiki/%E3%82%AA%E3%83%B3%E3%83%88%E3%83%AD%E3%82%B8%E3%83%BC_(%E6%83%85%E5%A0%B1%E7%A7%91%E5%AD%A6))

* 🎩トム・グルーバーが提唱。

* 知識を体系化する方法論で、「概念化の明示的な仕様」（知識を記述するための仕様）と定義されている。

* 知識の形式表現であり、あるドメインにおける概念間の関係のセットである。

* is-a 関係（上位概念、下位概念、推移律）、part-of 関係を用いる。

### ✅ [セマンティックウェブ](https://ja.wikipedia.org/wiki/%E3%82%BB%E3%83%9E%E3%83%B3%E3%83%86%E3%82%A3%E3%83%83%E3%82%AF%E3%83%BB%E3%82%A6%E3%82%A7%E3%83%96)

* [W3C](https://d.hatena.ne.jp/keyword/W3C) の🎩ティム・バーナーズ＝リーによって提唱されたプロジェクト。

* ウェブページの意味を扱うことができる「標準」や「ツール群」の開発により、ワールド・ワイド・ウェブの利便性を向上させようというもので、オントロジーを利用する。

* プロジェクトの目的は、ウェブページの閲覧という行為（データ交換）に対し、意味の疎通を付け加えることにある。

* 情報リソースに意味を付与することで、コンピュータで高度な意味処理を実現したり、文書の意味に即した処理が行えるようにする。

### ✅ ヘビーウェイトオントロジー（重量オントロジー）

* 人間が厳密にしっかりと考えて知識を記述していくアプローチ。

* 構成要素や意味的関係の正統性については、哲学的な考察が必要。

### ✅ ライトウェイトオントロジー（軽量オントロジー）

* コンピュータにデータを読み込ませ、自動で概念間の関係性を見つけるアプローチ。

* 完全に正でなくても使えればOKと考える。

* **ウェブマイニング**、**データマイニング**で利用される。

    ```
    ウェブマイニング（web mining）とは、
    ウェブサイトの構造やウェブ上のデータを利用して行うデータマイニングのことである。（引用）

    データマイニング（Data mining）とは、
    統計学、パターン認識、人工知能等のデータ解析の技法を大量のデータに網羅的に適用することで知識を取り出す技術のことである。（引用）
    ```

### ✅ 💻ワトソン

* IBM Watson

* Question-Answering（質問応答）型。

* 2011年、アメリカのクイズ番組である「[ジェパディ！](https://ja.wikipedia.org/wiki/%E3%82%B8%E3%82%A7%E3%83%91%E3%83%87%E3%82%A3!」で優勝した。

* ライトウェイトオントロジーに該当する。

    ![](https://assets.media-platform.com/bi/dist/images/2019/11/18/5dceff793afd373944079d27-w1280.png)

### ✅ 💻東ロボくん

* 2011年～2016年、国立情報学研究所。

* プロジェクトリーダーは🎩新井紀子。（著書『[AI vs.教科書が読めない子どもたち](https://www.amazon.co.jp/dp/4492762396』）

* 読解力に問題があり、何かしらのブレイクスルーが必要と判断され、開発は凍結された。

* その後、新井氏は人間側の読解力の問題に注目し、さまざまな活動を行っている。（[TED](https://www.ted.com/talks/noriko_arai_can_a_robot_pass_a_university_entrance_exam?language=ja)がわかりやすい）

# 2-3.📘機械学習

* ビッグデータを活用する。

* 統計的自然言語処理を行う。

* 応用例：

    レコメンデーションエンジン、スパムフィルター

## レコメンデーションシステム

* おすすめを提示するシステム。

### ✅ 協調ベースフィルタリング

* ユーザーの購買履歴からおすすめを表示するアプローチ。

* ユーザーの行動をもとにレコメンドする。

### ✅ 内容ベースフィルタリング

* アイテムの特徴をもとにおすすめを表示するアプローチ。

* 検索キーワードに関連する類似アイテムをレコメンドする。

* アイテムの特長ベクトルをもとにレコメンドである。

# 2-4.📘深層学習（ディープラーニング）

## 深層学習　関連手法

### ✅ 単純パーセプトロン

* シンプルなニューラルネットワーク。

* ステップ関数で表現できるがニューラルネットワークでは利用できない。

    ![](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Dirac_distribution_CDF.svg/1920px-Dirac_distribution_CDF.svg.png)

### ✅ ディープラーニング

* ニューラルネットワークを多層にしたもの。

### ✅ バックプロパゲーション

* 誤差逆伝播学習法

* ニューラルネットワークの学習におけるアルゴリズム。

### ✅ 自己符号化器（オートエンコーダ）

* 入力したものと同じものを出力して学習する。

## 深層学習　実装例

### ✅ 💻SuperVision

* 2012年、トロント大学、🎩ジェフリー・ヒントン。

* ILSVRC（Imagenet Large Scale Visual Recognition Challenge）2012 で勝利した。

* エラー率は26%台から15.3%へ劇的に改善。

* その後、2015年に人間の認識率（約5.1%）を抜いた。

* AlexNet（畳み込みニューラルネットワーク、CNN）を採用。

* 前年度まではサポートベクターマシンが主流だったが、ここからCNNに切り替わったことになる。

# ３．📘人工知能分野の問題

# 3-1.📘トイプロブレム（おもちゃの問題）

* ルールが決まっている問題（迷路、オセロなど）は解けても、現実世界に存在する複雑な問題は解けないという問題。

# 3-2.📘[フレーム問題](https://ja.wikipedia.org/wiki/%E3%83%95%E3%83%AC%E3%83%BC%E3%83%A0%E5%95%8F%E9%A1%8C)

* 1969年、🎩ジョン・マッカーシーと🎩パトリック・ヘイズが提唱。

* 人工知能における重要な難問の一つ。

* 有限の情報処理能力しかないロボットには、現実に起こりうる問題全てに対処することができない。

* 🎩ダニエル・デネット：

    考えすぎて何も解決できないロボットを例示し、フレーム問題の難しさを伝えた。

# 3-3.📘強いAI・弱いAI

* 🎩ジョン・サールが提唱。

* 強いAI：

    人間のような心、自意識を持つAI。

* 弱いAI：

    便利な道具であればよいという考え方によるAI。

## 汎用AI、特化型AI

### ✅ 汎用AI

* フレーム問題を打ち破るAIのことで、人間のように様々な課題に対処することができる。

### ✅ 特化型AI

* フレーム問題を打ち破っていないAIのこと。

## 強いAIに関する主張

### ✅ 中国語の部屋

* 🎩ジョン・サールが論文で発表した。

* 強いAIは実現不可能だという思考実験。

    ```
    中国語を理解できない人を小部屋に閉じ込めて、
    マニュアルに従った作業をさせるという内容。
    チューリング・テストを発展させた思考実験で、意識の問題を考えるのに使われる。（引用）
    ```

### ✅ 🎩ロジャー・ペンローズ

* イギリス生まれの数学者、宇宙物理学・理論物理学者。

* 「量子効果が絡んでいるため強いAIは実現できない」と主張した。

# 3-4.📘身体性

* 知能の成立には身体が不可欠であるという考え方。

* 物理的な身体により外部環境との相互作用を行うことができる。

* しかし、GoogleやFacebookの研究スピードでは、身体性の研究をすっ飛ばして概念獲得や意味理解ができてしまう可能性もある。

# 3-5.📘シンボルグラウンディング問題

* 🎩スティーブン・ハルナッド。

* 記号（シンボル）と現実世界の意味はどのようにして結びつけられるのかという問題。

* 外部世界を内部化（記号化、シンボル化）した時点で、外界との設置（クラウディング）が切れてしまうという問題。

### ✅ 知識獲得のボトルネック

* 人間が持っている知識は膨大であり、それらを獲得することは困難である。

* 特にエキスパートシステムの開発において問題となった。

### ✅ ニューラル機械翻訳

* NMT、Neural Machine Translation

* ニューラルネットワーク、ディープラーニングを利用した機械翻訳。

* 日本語の翻訳品質を飛躍的に高めた。

* 従来の方式には**ルールベース機械翻訳（RMT）**、**統計的機械翻訳（SMT）**がある。

    ```
    「ルールベース機械翻訳（RMT：Rule Based Machine Translation）」は、
    登録済みのルールを適応することで原文を分析し、訳文を出力する機械翻訳の方法です。
    
    「統計的機械翻訳（SMT：Statistical Base Machine Translation）」は、
    コンピュータに学習用の対訳データを与え、統計モデルを学習させることで訳文を出力させる方法です。（引用）
    ```

### ✓ seq2seq

* 再帰型ニューラルネットワーク（RNN）を使った文の生成モデル。

* 時系列データを入力し、時系列データを出力する。

* 別の言語に置き換えたり（翻訳）、質問を回答に置き換えたり（質問・回答）できる。

# 3-6.📘特徴量設計

* モデルの性能は、注目すべきデータの特徴（特徴量）の選び方により決定づけられるが、それを人間が見つけ出すのは難しい。

* 機械学習自身に発見させるアプローチを特徴表現学習という。

# 3-7.📘[チューリングテスト](https://ja.wikipedia.org/wiki/%E3%83%81%E3%83%A5%E3%83%BC%E3%83%AA%E3%83%B3%E3%82%B0%E3%83%BB%E3%83%86%E3%82%B9%E3%83%88)

* 🎩アラン・チューリングにより考案された。

* ある機械が知的かどうか（人工知能であるかどうか）を判定するためのテスト。

### ✅ ローブナーコンテスト

* [ローブナー賞](https://ja.wikipedia.org/wiki/%E3%83%AD%E3%83%BC%E3%83%96%E3%83%8A%E3%83%BC%E8%B3%9E)

* [Official Page](https://aisb.org.uk/aisb-events/)

* チューリングテストの合格を目指すコンテスト。

# 3-8.📘シンギュラリティ（技術的特異点）

* 🎩レイ・カーツワイルの著書で提唱された。

    * 2029年：人工知能が人間よりも賢くなる

    * 2045年：シンギュラリティの到来（2045年問題ともいわれる）

* 「収穫加速の法則」により「強いAI」が実現され、人間には予測不可能な変化が起こるとされている。

### ✓ [収穫加速の法則](https://ja.wikipedia.org/wiki/%E5%8F%8E%E7%A9%AB%E5%8A%A0%E9%80%9F%E3%81%AE%E6%B3%95%E5%89%87)

* レイ・カーツワイルが提唱した経験則。

* 一つの重要な発明が他の発明と結び付くことで、次の重要な発明の登場までの期間を短縮する。これによりイノベーションの速度が加速され、科学技術は直線的ではなく指数関数的に進歩するというもの。

### ✓ シンギュラリティに関する発言等

* 🎩レイ・カーツワイル	
    
    シンギュラリティは2045年に到来する

* 🎩ヒューゴ・デ・ガリス

    シンギュラリティは21世紀の後半に来る

* 🎩オレン・エツィオーニ

    シンギュラリティの終末論的構想は馬鹿げている

* 🎩ヴィーナー・ヴィンジ

    機械が人間の役に立つふりをしなくなること

* 🎩スティーブン・ホーキング

    AIの完成は人類の終焉を意味するかもしれない

* 🎩イーロン・マスク

    危機感を持ち非営利のAI研究組織 OpenAI を設立。

    OpenAI Gym（強化学習のシミュレーション環境）を発表。

# ４．📘機械学習の具体的手法

# 4-1.📘代表的な手法

## ✅ 教師あり学習

### ✓ 回帰問題

* [線形回帰 (linear regression)](https://ja.wikipedia.org/wiki/%E7%B7%9A%E5%BD%A2%E5%9B%9E%E5%B8%B0)

    ![](https://upload.wikimedia.org/wikipedia/commons/b/be/Normdist_regression.png)

    * 統計学における回帰分析の一種。

    * 特徴：通常の線形回帰は過学習を起こしやすい。ラッソ回帰やリッジ回帰で過学習を抑制する。

* 回帰分析の種類

    * 単回帰分析 ： ひとつの説明変数により、ひとつの目的変数を予測する。
    
    * 重回帰分析 ： 複数の説明変数から、ひとつの目的変数を予測する。

        + 多重共線性 ： 説明変数の選択において、相関係数の絶対値が最大値に近い特徴量のペアを選ぶと、予測の精度が悪化する性質。

+ [ラッソ回帰 (lasso regression)](https://ja.wikipedia.org/wiki/%E3%83%A9%E3%83%83%E3%82%BD%E5%9B%9E%E5%B8%B0)

    * 直線回帰に正則化項（L1ノルム）を加えた回帰分析。

* リッジ回帰 (ridge regression)

    * 直線回帰に正則化項（L2ノルム）を加えた回帰分析。

* 参考資料

    * ノルム ： いろいろなものの「大きさ」を表す。

    * [多重共線性とは？ 〜 概要と対応方法 〜](https://xica.net/vno4ul5p/)

### ✓ 分類問題

* ロジスティック回帰 (logistic regression)

    * 活性化関数として シグモイド関数 を使い、重回帰分析により二値分類を行う。

        * シグモイド関数は 対数オッズ（ロジット） の逆関数である。（ロジット変換（正規化））

        * 対数をとる前の オッズ とは、ある事象が起こる確率 p と起こらない確率 1−p の比のこと。

        * 最小化を行う関数として **尤度関数** が用いられる。

* 多クラスロジスティック回帰

    * 活性化関数に **ソフトマックス関数** を利用し、多クラス分類を行う。

* ランダムフォレスト (random forest)

    * ブートストラップサンプリングにより、アンサンブル学習を行う。

    * バギングに該当する。

    * バギング

        * データ全体からランダムに一部データを用いて、複数のモデルを作る（学習する）方法。並列処理になる。

    * ブースティング (boosting)

        * 一部のデータを繰り返し抽出し、複数のモデルを学習させる。

        * 逐次処理のため、ランダムフォレストより時間がかかる。

        * AdaBoost、勾配ブースティング、XgBoost

* サポートベクターマシン

    * コンセプトはマージンの最大化を行うこと。

    * スラック変数
    
        * 誤分類を許容する工夫をする、線形分離不可能なデータのマージンを最大化する。

    * カーネル法

        * カーネル関数により高次元への写像を行い線形分離可能にする。

            [![](https://miro.medium.com/max/2400/1*mCwnu5kXot6buL7jeIafqQ.png)](https://medium.com/@zxr.nju/what-is-the-kernel-trick-why-is-it-important-98a98db0961d)


    * カーネルトリック

        * 写像の際に計算が複雑にならないように式変形するテクニック。計算量を大幅に削減する。

* ニューラルネットワーク

    * キーワード：

        ニューロン、神経回路、単純パーセプトロン、多層パーセプトロン、入力層、出力層、重み、隠れ層、活性化関数、シグモイド関数、誤差逆伝播法

    * ロジスティック回帰はニューラルネットワークの一種。（単純パーセプトロンと同等）

## ✅ 教師なし学習

* k-means法

    * クラスタリングの手法。

        * 課題：クラスタリングを行う処理の初期値の取り方により結果が異なる。（偏りが生じる）

        * kNN法はクラス分類（教師あり学習）の手法なので注意！

* k-means++

    * k-meansの課題である初期値の取り方を工夫することにより、結果に偏りが生じることを抑制する。

* 主成分分析（PCA）

    * **次元削減**の手法のひとつ。

    * 相関のある多数の変数から、特徴をよく表している成分（主成分）を特定し要約することで次元を削減する。

    * 寄与率：各成分の重要度を表す。

## ✅ 強化学習

* エージェントの目的は収益（報酬・累積報酬）を最大化する方策を獲得すること。

* エージェントが行動を選択することで状態が変化し、最良の行動を選択する行為を繰り返す。

* 状態 →（方策により）行動 → 収益を獲得 → 次の状態 →・・・

# 4-2.📘データの扱い

* ホールドアウト検証

    * データを訓練データとテストデータに分割（例えば７：３）し利用する。

    * 訓練データでの学習によりモデルを構築し、テストデータで検証を行う。

    * 交差検証の一種と説明されることもあるが、データを交差させないため交差検証ではない。

* k-分割交差検証

    * テストデータをk個に分割し、ひとつをテストデータ、その他を訓練データとする。

    * テストデータを順次入れ替えることで、少ないテストデータでもより安定したモデルを選択できる。

* 訓練データ、検証データ、テストデータ

    * 訓練データによる学習でモデルを作成する。

    * 検証データによりハイパーパラメータ等を調整する。

    * テストデータにより評価を行う。

## ✅ 欠損値処理

### ✓ リストワイズ法

* 欠損があるサンプルをそのまま削除する方法。

* 欠損に偏りがある場合はデータの傾向を変えてしまうので注意が必要。

### ✓ 回帰補完

* 欠損しているある特徴量と相関が強い他の特徴量が存在している場合に有効。

## ✅ カテゴリデータ

### ✓ マッピング

* 順序を持つデータの場合、数値の辞書型データにマッピングする。

### ✓ ワンホットエンコーディング

* 順序を持たないデータの場合、各カテゴリごとにダミー変数を割り当てる。

# 4-3.📘応用・評価指標

## ✅ 混同行列

* 正解率 ： 陽性・陰性を含めた全正解数に対する、予測での正解数。全体の精度を上げたい場合の評価項目。

* 適合率 ： 予測での陽性数に対する、実際の陽性数（陽性だ！と思ったものがどれくらい合っているか）。偽陽性を削減したい場合の評価項目。

* 再現率 ： 実際の全陽性に対する、予測での陽性正解数（すべての陽性に対し、予測でどれくらい陽性が再現できているか）。偽陰性を削減したい場合の評価項目。適合率と再現率は相反関係にある。

* F値 ： 適合率と再現率の調和平均。

## ✅ オーバーフィッティング、アンダーフィッティング

* オーバーフィッティング

    * 訓練データに適合しすぎており（過学習）、テストデータの精度が低下している状態。（汎化性能が低い状態）

    * 訓練データにフィットしすぎないように、正則化項の導入などを行ったのち、改めて学習を行う必要がある。

* アンダーフィッティング

    * 訓練が不十分で、訓練データ・テストデータの両方に対して精度が低い状態。

    * 学習をさらに進めることで改善することがある。

## ✅ 正則化

* 訓練誤差ではなく、汎化誤差を小さくする（汎化性能を高める）ための手法。正則化項を導入することでオーバーフィッティグを防止する。

* L1正則化：ラッソ正則化（Lasso Normalization）。不要なパラメータを削減できる（ゼロにする）。この特徴をスパース性という。

* L2正則化：リッジ回帰（Ridge Normalization）。Lassoと違い特徴量の選択は行わないが、パラメータのノルムを小さく抑えることができる（パラメータのノルムにペナルティを課す）。重み減衰（Weight Decay）ともいう。

* Elastic Net：L1正則化、L2正則化を組み合わせたもの。

* 参考：[Qiita-【機械学習】ラッソ回帰・リッジ回帰について　メモ](https://qiita.com/nanairoGlasses/items/57515340a1bc24ffe445#%E3%83%A9%E3%83%83%E3%82%BD%E5%9B%9E%E5%B8%B0%E3%81%A8%E3%81%AF)

# ５．📘ディープラーニングの概要

# 5-1.📘ニューラルネットワークとディープラーニング

## ✅ 単純パーセプトロン

* 線形分類しかできない。

    ![](https://miro.medium.com/max/645/0*LJBO8UbtzK_SKMog)

## ✅ 多層パーセプトロン

* 多層化することで、非線形分類が出来るようになった。

    ![](https://miro.medium.com/max/700/1*-IPQlOd46dlsutIbUq1Zcw.png)

## ✅ ディープラーニング

* 概念としては1960年代には既に存在していた。

* ディープニューラルネットワークを用いたもので、ニューロンをいくつもつなげており、複雑な関数を近似できる。

* 検証方法として、通常はデータ量が多いため、ホールドアウト検証でよい（十分である）。

* 問題：

    * オーバーフィッティング（過学習）しやすい。（但し、精度に特別バラつきが出やすいというわけではない。）

    * 勾配消失問題を起こしやすい。

    * 事前に調整すべきパラメータ数が非常に多い。

## ✅ 用語

* バッチサイズ

    * イテレーションで用いるデータセットのサンプル数。

    * 全データをバッチサイズで切り分ける。

* イテレーション

    * 重みの更新を行う回数。

    * データセットに含まれるデータが少なくとも１回は実行されるようにする学習回数。

    * データセットとバッチサイズが決まれば、イテレーションは自動的に決まる。

        * イテレーション＝データセット／バッチサイズ

* エポック

    * 訓練データを学習に用いた回数。

    * データセットのバッチサイズ分割からイテレーション実行までの処理を繰り返す回数のこと。

    * エポック数が２の場合、データセットを２回使うことになる。（重みの更新回数＝イテレーション数×バッチ数×２）

* 参考

    * [機械学習／ディープラーニングにおけるバッチサイズ、イテレーション数、エポック数の決め方 - Qiita](https://qiita.com/kenta1984/items/bad75a37d552510e4682)

        ![](https://miro.medium.com/max/700/1*AOiD8LEDWrWy5l_f9qgweQ@2x.jpeg)

# 5-2.📘既存のニューラルネットワークにおける問題

* 課題

    * 隠れ層の層数を増やすと、誤差逆伝播時に誤差が最後（入力層付近）まで正しく反映されない。

* 原因

    * シグモイド関数の導関数（微分式）の最大値は0.25のため、層を進ごとに伝播させる誤差の値がどんどんと小さくなってしまう。（**勾配消失問題**）

        * 0.25×0.25×0.25… と計算していくと値が小さくなっていく。

# 5-3.📘ディープラーニングのアプローチ

## ✅ オートエンコーダ（autoencoder、自己符号化器）

* 🎩ジェフリー・ヒントンが提唱。

* 入力と出力が同じになるニューラルネットワーク。（＝正解ラベルが入力と同じ）

* 次元削減が行える。

    ![](https://upload.wikimedia.org/wikipedia/commons/3/34/%D0%90%D0%B2%D1%82%D0%BE%D1%8D%D0%BD%D0%BA%D0%BE%D0%B4%D0%B5%D1%80.png)

## ✅ 積層オートエンコーダ

* オートエンコーダを積み重ねて、逐次的に学習させる（事前学習）ことで重みを調整する

## ✅ ファインチューニング

* 積層オートエンコーダにロジスティック回帰層（あるいは線形回帰層）を追加し、仕上げの学習を行う。

# 参考

以下のサイトからの情報をもとに個人でまとめました。

* [【資格試験対策】ディープラーニングG検定【キーワード・ポイントまとめ】](https://sik-bug.hatenablog.com/entry/2020/05/30/103038)
